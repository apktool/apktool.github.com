<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>HBase进阶 on acronymor&#39;s blog</title>
    <link>http://acronymor:80/categories/hbase%E8%BF%9B%E9%98%B6/</link>
    <description>Recent content in HBase进阶 on acronymor&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 15 Apr 2021 22:47:00 +0800</lastBuildDate><atom:link href="http://acronymor:80/categories/hbase%E8%BF%9B%E9%98%B6/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>HBase Compaction流程说明</title>
      <link>http://acronymor:80/posts/hbase/chapter2/compaction/</link>
      <pubDate>Thu, 15 Apr 2021 22:47:00 +0800</pubDate>
      
      <guid>http://acronymor:80/posts/hbase/chapter2/compaction/</guid>
      <description>Compaction涉及到的模块说明    Compaction种类    Compaction会从一个region的一个store中选择一些hfile文件进行合并。合并说来原理很简单，先从这些待合并的数据文件中读出KeyValues，再按照由小到大排列后写入一个新的文件中。之后，这个新生成的文件就会取代之前待合并的所有文件对外提供服务。HBase根据合并规模将Compaction分为了两类：MinorCompaction和MajorCompaction。
Minor Compaction    选取一些小的、相邻的StoreFile将他们合并成一个更大的StoreFile，在这个过程中不会处理已经Deleted或Expired的Cell。一次Minor Compaction的结果是更少并且更大的StoreFile。
Major Compaction    将所有的StoreFile合并成一个StoreFile，这个过程还会清理三类无意义数据：被删除的数据、TTL过期数据、版本号超过设定版本号的数据。另外，一般情况下，Major Compaction时间会持续比较长，整个过程会消耗大量系统资源，对上层业务有比较大的影响。因此线上业务都会将关闭自动触发Major Compaction功能，改为手动在业务低峰期触发。
Compaction的流程介绍    Compaction的整个流程中涉及到了非常重要的几个组件，StoreEngine，CompactionContext，CompactionPolicy，Compactor。
CompactionContext决定了StoreFile的选取策略(CompactionPolicy)，也决定了StoreFile的合并策略(Compactor)。而CompactionContext最终由StoreEngine初始化（读取配置，通过反射的方式创建对应的类）。
1 2 3 4  hbase.hstore.defaultengine.storeflusher.class=DefaultStoreFlusher.class hbase.hstore.engine.class=DefaultStoreEngine.class hbase.hstore.defaultengine.compactor.class=DefaultCompactor.class hbase.hstore.defaultengine.compactionpolicy.class=ExploringCompactionPolicy.class   CompactionContext是个抽象类，有三个非常重要的方法preSelect，select，compact。
preSelect方法在coprocessor的preCompactSelection方法之间调用，主要是为coprocessor过滤一些storefile（比如排除掉那些明显本次就不会被compac的文件）。 select方法由compaction选择文件时调用，一般会依赖具体的算法实现，最后与compact方法配合使用。
Compaction触发时机    HBase 中可以触发 compaction 的因素有很多，最常见的因素有这么三种: MemStore Flush、后台线程周期性检查、手动触发。
MemStore Flush    应该说compaction操作的源头就来自flush操作，memstore flush会产生HFile文件，文件越来越多就需要compact。因此在每次执行完Flush操作之后，都会对当前Store中的文件数进行判断，一旦文件数大于等于 hbase.hstore.compactionThreshold ，就会触发compaction。需要说明的是，compaction都是以Store为单位进行的，而在Flush触发条件下，整个Region的所有Store都会执行compact，所以会在短时间内执行多次compaction。
后台线程周期性检查    后台线程CompactionChecker定期触发检查是否需要执行compaction，检查周期为：hbase.server.thread.wakefrequency * hbase.server.compactchecker.interval.multiplier。和flush不同的是，该线程优先检查文件数是否大于 hbase.</description>
    </item>
    
    <item>
      <title>HBase MVCC</title>
      <link>http://acronymor:80/posts/hbase/chapter2/mvcc/</link>
      <pubDate>Thu, 15 Apr 2021 22:23:00 +0800</pubDate>
      
      <guid>http://acronymor:80/posts/hbase/chapter2/mvcc/</guid>
      <description>Reference     HBase 行锁与多版本并发控制 (MVCC) HBASE-12751  </description>
    </item>
    
    <item>
      <title>HBase Scan 流程说明</title>
      <link>http://acronymor:80/posts/hbase/chapter2/scan/</link>
      <pubDate>Thu, 01 Apr 2021 00:04:30 +0800</pubDate>
      
      <guid>http://acronymor:80/posts/hbase/chapter2/scan/</guid>
      <description>Scan涉及到的模块说明    Scan 操作的RPC消息结构    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  message Scan { repeated Column column = 1; repeated NameBytesPair attribute = 2; optional bytes start_row = 3; optional bytes stop_row = 4; optional Filter filter = 5; optional TimeRange time_range = 6; optional uint32 max_versions = 7 [default = 1]; optional bool cache_blocks = 8 [default = true]; optional uint32 batch_size = 9; optional uint64 max_result_size = 10; optional uint32 store_limit = 11; optional uint32 store_offset = 12; optional bool load_column_families_on_demand = 13; optional bool small = 14 [deprecated = true]; optional bool reversed = 15 [default = false]; optional Consistency consistency = 16 [default = STRONG]; optional uint32 caching = 17; optional bool allow_partial_results = 18; repeated ColumnFamilyTimeRange cf_time_range = 19; optional uint64 mvcc_read_point = 20 [default = 0]; optional bool include_start_row = 21 [default = true]; optional bool include_stop_row = 22 [default = false]; enum ReadType { DEFAULT = 0; STREAM = 1; PREAD = 2; } optional ReadType readType = 23 [default = DEFAULT]; optional bool need_cursor_result = 24 [default = false];}  Scan 操作的流程介绍    scan过程总体上是分层处理的，与存储上的组织方式一致，脉络比较清晰； 具体来说，就是region -&amp;gt; store -&amp;gt; hfile/memstore，分别都有对应的scanner实现进行数据读取；</description>
    </item>
    
    <item>
      <title>HBase Put 流程说明</title>
      <link>http://acronymor:80/posts/hbase/chapter2/put/</link>
      <pubDate>Sat, 20 Mar 2021 00:14:00 +0800</pubDate>
      
      <guid>http://acronymor:80/posts/hbase/chapter2/put/</guid>
      <description>Put涉及到的模块说明    HBase采用LSM树架构，天生适用于写多读少的应用场景。在真实生产线环境中，也正是因为HBase集群出色的写入能力，才能支持当下很多数据激增的业务。需要说明的是，HBase服务端并没有提供update、delete接口，HBase中对数据的更新、删除操作在服务器端也认为是写入操作，不同的是，更新操作会写入一个最新版本数据，删除操作会写入一条标记为deleted的KV数据。所以HBase中更新、删除操作的流程与写入流程完全一致。当然，HBase数据写入的整个流程随着版本的迭代在不断优化，但总体流程变化不大。
写入流程的三个阶段
从整体架构的视角来看，写入流程可以概括为三个阶段。
 客户端处理阶段：客户端将用户的写入请求进行预处理，并根据集群元数据定位写入数据所在的RegionServer，将请求发送给对应的RegionServer。 Region写入阶段：RegionServer接收到写入请求之后将数据解析出来，首先写入WAL，再写入对应Region列簇的MemStore。 MemStore Flush阶段：当Region中MemStore容量超过一定阈值，系统会异步执行flush操作，将内存中的数据写入文件，形成HFile。  用户写入请求在完成Region MemStore的写入之后就会返回成功。MemStoreFlush是一个异步执行的过程。
put操作的RPC消息结构    put操作的流程介绍    HBase Client的流程    HBase客户端处理写入请求的核心流程基本上可以概括为三步。
 用户提交put请求后，HBase客户端会将写入的数据添加到本地缓冲区中，符合一定条件就会通过AsyncProcess异步批量提交。HBase默认设置autoflush=true，表示put请求直接会提交给服务器进行处理；用户可以设置autoflush=false，这样，put请求会首先放到本地缓冲区，等到本地缓冲区大小超过一定阈值（默认为2M，可以通过配置文件配置）之后才会提交。很显然，后者使用批量提交请求，可以极大地提升写入吞吐量，但是因为没有保护机制，如果客户端崩溃，会导致部分已经提交的数据丢失。 在提交之前，HBase会在元数据表hbase:meta中根据rowkey找到它们归属的RegionServer，这个定位的过程是通过HConnection的locateRegion方法(下图中的getRegionLocation方法最终调用到的方法)完成的。如果是批量请求，还会把这些rowkey按照HRegionLocation分组，不同分组的请求意味着发送到不同的RegionServer，因此每个分组对应一次RPC请求。 HBase会为每个HRegionLocation构造一个远程RPC请求MultiServerCallable，并通过rpcCallerFactory. newCaller()执行调用。将请求经过Protobuf序列化后发送给对应的RegionServer。  备注     图中的 meta cache 基于 CopyOnWriteArrayMap 实现。
  客户端根据写入的表以及rowkey在元数据缓存中查找，如果能够查找出该rowkey所在的RegionServer以及Region，就可以直接发送写入请求（携带Region信息）到目标RegionServer。 如果客户端缓存中没有查到对应的rowkey信息，需要首先到ZooKeeper上/hbase/meta-region-server节点查找HBase元数据表所在的RegionServer。向hbase:meta所在的RegionServer发送查询请求，在元数据表中查找rowkey所在的RegionServer以及Region信息。客户端接收到返回结果之后会将结果缓存到本地，以备下次使用。 客户端根据rowkey相关元数据信息将写入请求发送给目标RegionServer，RegionServer接收到请求之后会解析出具体的Region信息，查到对应的Region对象，并将数据写入目标Region的MemStore中。  HBase Master的流程    HBase RegionServer的流程    数据写入Region的流程可以抽象为两步：追加写入HLog，随机写入MemStore
HLog追加写入    HLog保证成功写入MemStore中的数据不会因为进程异常退出或者机器宕机而丢失，但实际上并不完全如此，HBase定义了多个HLog持久化等级，使得用户在数据高可靠和写入性能之间进行权衡。
HLog持久化等级    HBase可以通过设置HLog的持久化等级决定是否开启HLog机制以及HLog的落盘方式。HLog的持久化等级分为如下五个等级。</description>
    </item>
    
    <item>
      <title>HBase RPC 流程说明</title>
      <link>http://acronymor:80/posts/hbase/chapter2/rpc/</link>
      <pubDate>Mon, 15 Mar 2021 00:14:00 +0800</pubDate>
      
      <guid>http://acronymor:80/posts/hbase/chapter2/rpc/</guid>
      <description>引入RPC    RPC的基本概念    RPC（Remote Procedure Call）远程过程调用，它是一种技术思想，而非规范或者协议。从效果上来看，A节点应用可以像调用本地方法一样调用B节点服务的方法。为了达到这样的目的，需要解决通讯问题，序列化和反序列化问题，寻址问题等等。
上图中的Stub类似于一个代理，一般的使用方法是response = stub.scan(controller, request)，比如在A节点的应用中使用stub.scan(...)实际上调用的就是B节点上指定服务的方法。
RPC的实现需要解决序列化和反序列化问题，在日常的开发中，这一块借由protobuf定义的message实现；寻址问题则借protobuf定义的service实现；通讯问题借助Netty实现。
RPC涉及到的模块说明    HBase整个RPC框架实现逻辑较为繁琐，不过依旧没有偏离上述的实现逻辑。
RPC操作的RPC消息结构    HBase RPC操作的流程介绍    HBase Client的流程    上图的流程被绿色和蓝色的线分割成了三部分，最左边的一部分完成了调度执行的功能，中间的部分完成了服务代理的功能，最右边的部分完成了通信模块的功能。
调度执行    该模块主要提供接口转换、错误重试、服务分组等能力；
 接口转换  服务层定义的服务接口与用户层不同，比如put/delete/increment/append等操作底层都是调用的mutate接口，而batch相关的操作，无论是读还是写都调用multi接口；
转换逻辑封装为一个Callable对象，交由RpcRetryingCaller处理；
错误重试  RpcRetryingCaller负责与服务代理模块直接交互 ，以及错误时的重试；
服务分组  batch相关的操作可能会涉及到多个RegionServer，需要按照RegionServer进行分组，然后多线程并发请求，这些逻辑是在AsyncProcess中；
对于非batch类请求则直接使用RpcRetryingCaller进行调用，AsyncProcess的内部实际上也是依赖了该类来执行单个RegionServer请求；
服务代理    服务代理实现了与服务端同样的接口； 对调度执行模块而言，调用stub的方法就相当于调用远程的服务，而不必关心实现细节；
这部分依赖protobuf组件，通过在proto文件中定义service及message类型的参数，可直接生成接口和stub实现类；
在ConnectionImplementation类中有一个Map类型的stubs变量，其key为service name + regionserver，value则是stub实例；
通信模块    该模块主要进行序列化和io处理；</description>
    </item>
    
    <item>
      <title>HBase CreateTable 流程说明</title>
      <link>http://acronymor:80/posts/hbase/chapter2/create-table/</link>
      <pubDate>Wed, 10 Mar 2021 23:14:00 +0800</pubDate>
      
      <guid>http://acronymor:80/posts/hbase/chapter2/create-table/</guid>
      <description>CreateTable涉及到的模块说明    创建表的整个流程主要分为两大块，一大块是Client端，主要用于构造RPC请求，另一大块是Master端，主要负责实际的建表流程。
整个流程借助上图还是比较容易理解的。因为Procedure v2框架的引入，客户端根据需要仅仅发送请求便可，然后实际的建表就交给Procedure v2进行实际的操作。
创建表的RPC消息结构    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  message TableSchema { optional TableName table_name = 1; repeated BytesBytesPair attributes = 2; repeated ColumnFamilySchema column_families = 3; repeated NameStringPair configuration = 4;}message CreateTableRequest { required TableSchema table_schema = 1; repeated bytes split_keys = 2; optional uint64 nonce_group = 3 [default = 0]; optional uint64 nonce = 4 [default = 0];}message CreateTableResponse { optional uint64 proc_id = 1;}service MasterService { /** Creates a new table asynchronously */ rpc CreateTable(CreateTableRequest) returns(CreateTableResponse); /** Deletes a table */ rpc DeleteTable(DeleteTableRequest) returns(DeleteTableResponse);}  创建表的流程介绍    1 2 3 4 5 6 7 8  public boolean create(TableDescriptor table) {  try (Admin admin = connection.</description>
    </item>
    
    <item>
      <title>HBase Procedure v2 原理说明</title>
      <link>http://acronymor:80/posts/hbase/chapter2/procedurev2-02/</link>
      <pubDate>Mon, 08 Mar 2021 21:01:00 +0800</pubDate>
      
      <guid>http://acronymor:80/posts/hbase/chapter2/procedurev2-02/</guid>
      <description>HBase Procedure v2之Procedure    Procedure类型       名称 说明     Meta Procedure execute(), rollback()   Server Procedure 唯一的一种类型为ServerCrashProcedure，用来负责RegionServer进程故障后的处理   Peer Procedure 与Replication相关，如AddPeerProcedure, RemovePeerProcedure等等   Table Procedure 类型最为丰富，如CreateTableProcedure, DisableTableProcedure, EnableTableProcedure, AssignProcedure, SplitTableRegionProcedure, &amp;hellip;涵盖表级别、Region级别的各类操作。    在ProcedureScheduler中，需要同时调度这几种类型的Procedure，调度的优先级顺序(由高到低)为：
 Meta -&amp;gt; Server -&amp;gt; Peer -&amp;gt; Table。
 Procedure状态       名称 说明     INITIALIZING Procedure in construction, not yet added to the executor   RUNNABLE Procedure added to the executor, and ready to be executed   WAITING The procedure is waiting on children to be completed   WAITING_TIMEOUT The procedure is waiting a timout or an external event   ROLLEDBACK The procedure failed and was rolledback   SUCCESS The procedure execution is completed successfully.</description>
    </item>
    
    <item>
      <title>HBase Procedure v2 原理说明</title>
      <link>http://acronymor:80/posts/hbase/chapter2/procedurev2-01/</link>
      <pubDate>Sun, 07 Mar 2021 21:01:00 +0800</pubDate>
      
      <guid>http://acronymor:80/posts/hbase/chapter2/procedurev2-01/</guid>
      <description>HBase Procedure v2介绍    HBase Procedure v2提供了一种对内的事务能力，注意这里是对内的事务。简单来说，这里不是HBase数据层面的事务，而是操作步骤层面的事务。在Procedure v2出来之前，HBase的操作过程处于一种伪事务的状态，同步操作的流程也处于一种伪同步的流程。在分布式的环境下，如果一个操作环节出现了问题，那么处理起来也非常棘手。
比如在Master中的CreateHandler()任务交给了线程池，并没有实现真正意义上的同步。而且如果CreateHander()的创建过程如果非常长，或者出现了失败，也没有足够的回滚机制来将Master中存储的信息会滚到之前的状态。这些在HBase的稳定性上面都存在极大的隐患，基于此，HBase社区与2.0.0引入Procedure V2来解决这一系列问题。 比如上图的问题，采用Procedure V2就可以实现为如下，将这个“伪异步”的线程作为一个procedure，当执行后，返回一个procId，然后客户端就可以根据这个procId确认该步骤是否完成。
HBase Procedure v2架构    整个Procedure v2模块分为图中所示的三大块，每块各司其主共同完成事务操作。 ProcedureExecutor首先会将Procedure提交给ProcedureStore完成持久化，接着由ProcedureScheduler从ProcedureStore获取合适的Procedure进行调度，最后将该合适的Procedure传递给ProcedureExecutor中的WorkerThread完成执行
涉及的核心方法    Procedure 相关的类均被定义在 hbase-procedure 包里面，目前也仅仅只有HMaster会用到。Procedure 的几个组成模块中，每个模块定义了几个非常重要的方法。
   名称 说明     Procedure execute(), rollback()   ProcedureExecutor sumitProcedure(Procedure), isFinished(procId), getResult(procId)   ProcedureStore load(Proc), insert(Proc), update(Proc), delete(Proc)    其中Procedure的execute()方法和rollback()方法，实现要求必须具有幂等性，即无论执行多少次，其结果应该是一样的。也正是因为这两个方法的存在，使得Procedure可以保证事务性。
Procedure    Procedure定义了具体的执行步骤，有点类似与执行模板/蓝图之类的概念，它并不能直接执行，只是定义好了每个步骤的状态，执行过程，最后由ProcedureExecutor对这些过程和状态描摹执行。
ProcedureExecutor    负责提交、执行Procedure。Procedure的执行操作，主要由其负责的多个WorkerThread来完成。</description>
    </item>
    
  </channel>
</rss>
